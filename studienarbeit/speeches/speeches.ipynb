{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Politische Reden als Datenquelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "from pandarallel import pandarallel\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "sns.set(style=\"white\", palette=\"muted\", rc={\"figure.figsize\": (20, 8)})\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAST_MODE = False\n",
    "data_dir = Path(\"../../data/speeches\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "\n",
    "Im Folgenden wird der [Datensatz bestehend aus Bundestagsreden](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/FIKIBO), bereitgestellt von [Open Discourse](https://opendiscourse.de/) initial untersucht. Politische Reden, in diesem Fall aus dem deutschen Bundestag, sollen als ein Standbein als Trainingsdaten für das Klassifikationsproblem genutzt werden. Der Datensatz bietet den Vorteil, dass eine große Menge an gelabelten Texten zur Verfügung steht sowie alle möglichen Themenbereiche abdeckt, die im Laufe der Jahre im Bundestag debattiert wurden. Da die Reden deutlich länger sind als Tweets (siehe unten), muss eine Lösung gefunden werden, wie die Redetexte aufgeteilt werden können, um sie dem Modell als Input zur Verfügung zu stellen. Andererseits kann dies auche als Vorteil gesehen werden, da die Reden deutlich mehr Informationen enthalten als Tweets und somit dem Modell eine bessere Chance bieten, auch aufgrund inhaltlichen Zusammenhängen zu entscheiden."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `factions`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_factions = pd.read_feather(data_dir / \"src\" / \"factions.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_factions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die `factions`-Datei verknüpft die ID der Parteien mit deren Namen. Für die für uns relevanten Parteien sollten wir uns frühzeitig auf ein einheitliches Mapping zwischen Label und Partei einigen, um spätere Probleme zu vermeiden.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `politicians`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_politicians = pd.read_feather(data_dir / \"src\" / \"politicians.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_politicians"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die `politicians`-Datei verknüpft die ID der Politiker mit deren Namen inkl. weiteren Informationen. Da wir zunächst nur nach Parteien klassifizieren wollen, ist diese Datei für uns nicht relevant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"faction\", data=df_politicians)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `electoral_terms`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_electoral_terms = pd.read_feather(data_dir / \"src\" / \"electoral_terms.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_electoral_terms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die `electoral_terms`-Datei verknüpft die ID der Wahlperioden mit derem Start- und Enddatum. Um in allen Datenquellen vergleichbare Themen, Sprache und Parteien zu haben, sollten alle Daten auf einen ähnlichen Zeitraum beschränkt werden. Da sich die uns zur Verfügung stehenden Tweet Daten auf die Bundestagswahl 2021 und die Wahlperiode 19 beziehen, sind vor allem Reden als der 19. Wahlperiode relevant.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `contributions`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contributions = pd.read_feather(data_dir / \"src\" / \"contributions_extended.feather\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `speeches`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches = pd.read_feather(data_dir / \"src\" / \"speeches.feather\", columns=[\"electoralTerm\", \"speechContent\", \"politicianId\", \"factionId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie gerade angemerkt, sind für uns erstmal die Reden aus der 19. Wahlperiode relevant:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches = df_speeches[df_speeches[\"electoralTerm\"] == 19].reset_index()\n",
    "df_speeches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus dieser Wahlperiode bleiben zunächst etwa 61.000 Reden übrig. Davon sind jedoch noch jene abzuziehen, die keiner Partei zugeordnet sind, weil beispielsweise das Präsidium des Bundestage gesprochen hat. Zudem wird mithilfe der `factionId` der Namen der Fraktion bestimmt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factions_of_interest = [0, 3, 4, 6, 13, 23]\n",
    "df_speeches = df_speeches[df_speeches[\"factionId\"].isin(factions_of_interest)]\n",
    "\n",
    "party_mapping = {\n",
    "    0: \"AfD\",\n",
    "    3: \"Grüne\",\n",
    "    4: \"Union\",\n",
    "    6: \"Linke\",\n",
    "    13: \"FDP\",\n",
    "    23: \"SPD\"\n",
    "}\n",
    "df_speeches[\"faction\"] = df_speeches[\"factionId\"].map(party_mapping)\n",
    "df_speeches = df_speeches.drop(columns=[\"factionId\"])\n",
    "\n",
    "df_speeches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somit reduziert sich die Anzahl an verbleibender Reden auf knapp 29.000.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da der Wert von `electoralTerm` nun konstant ist, kann die Spalte gelöscht werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches = df_speeches.drop(columns=[\"electoralTerm\"])\n",
    "df_speeches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Anzahl an Reden pro Fraktion`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn man sich die Anzahl an Reden pro Fraktion anschaut, fällt auf, dass die Fraktionen der CDU/CSU und der SPD deutlich mehr Reden haben als die anderen Parteien, was auch zu erwarten ist. Im Zuge der Data Preparation muss hierzu sichergestellt werden, dass ein Ungleichgewicht vermieden wird.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"faction\", data=df_speeches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_len = df_speeches[\"speechContent\"].str.len()\n",
    "df_len.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_len)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auffallend sie viele Reden mit keinem oder sehr wenigen Zeichen. Damit eine Rede auch inhaltlich verarbeitet werden kann, muss im Zuge der Data Preparation eine Mindestlänge festgelegt werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches = df_speeches[df_speeches[\"speechContent\"].str.len() > 400]\n",
    "df_speeches = df_speeches[df_speeches[\"speechContent\"].str.len() < 7000]\n",
    "df_speeches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setzt man beispielsweise voraus, dass jede Rede mindestens 100 Zeichen umfassen muss, so bleiben immer noch etwa 26.500 Reden übrig."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es fällt zudem auf, dass die meisten Reden mit einer Anrede an den Bundestagspräsidenten und das Plenum beginnen sowie mit einem Dank zum Schluss aufhören. Hier ist fraglich, inwieweit diese Anreden und Danksagungen relevant sind. Im Zuge der Data Preparation muss hierzu eine Entscheidung getroffen werden und gegebenenfalls versucht werden, diese Passagen zu entfernen, damit die Reden nur die inhaltlichen Ausführungen enthalten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test if maximum number of tokens (512 for BERT based models) is exceeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"oliverguhr/german-sentiment-bert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches[\"num_tokens\"] = df_speeches[\"speechContent\"].apply(lambda x: len(tokenizer.encode(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches[\"num_tokens\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce(lambda a, b: set((*a, *b)), df_speeches[\"speechContent\"].apply(np.array))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schaut man sich an, welche Zeichen in den Reden vorkommen, fällt auf, dass neben dem regulären Alphabet auch einige unerwünschte Sonderzeichen enthalten sind, die im Zuge der Data Preparation entfernt werden müssen.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from studienarbeit.utils.cleaning import CleanText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = pd.read_feather(data_dir / \"src\" / \"speeches.feather\", columns=[\"electoralTerm\", \"speechContent\", \"factionId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_mapping = {\n",
    "    0: 0,   # AfD\n",
    "    3: 2,   # Grüne\n",
    "    4: 5,   # Union\n",
    "    6: 3,   # Linke\n",
    "    13: 1,  # FDP\n",
    "    23: 4,  # SPD\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep[\"party\"] = df_prep[\"factionId\"].map(party_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_cleaning(text):\n",
    "    text = re.sub(\"[\\u2022\\u2023\\u25E6\\u2043\\u2219\\uf0b7\\u25fc]\\s\", \"\", text)\n",
    "    text = re.sub(\"({\\d*})\", \"\", text)\n",
    "    text = re.sub(\"\\(\\w*\\)\", \"\", text)\n",
    "    text = text.replace(\". –\", \".\")\n",
    "    \n",
    "    text = re.sub(\"\\n\", \" \", text)\n",
    "    text = re.sub(\"\\t\", \" \", text)\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep[\"init_clean\"] = df_prep[\"speechContent\"].parallel_apply(lambda x: initial_cleaning(x))\n",
    "df_prep = df_prep.drop(columns=[\"speechContent\", \"factionId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FAST_MODE and (data_dir / \"cache/speeches_prep.feather\").exists():\n",
    "    df_prep = pd.read_feather(data_dir / \"cache/speeches_prep.feather\")\n",
    "else:\n",
    "    clean = CleanText()\n",
    "  \n",
    "    df_prep[\"clean_text\"] = df_prep[\"init_clean\"].parallel_apply(lambda x: clean.clean_text(x, True))\n",
    "    df_prep[\"tokenized_text\"] = df_prep[\"clean_text\"].parallel_apply(lambda x: clean.remove_stopwords(clean.stemm_text(x)))\n",
    "    \n",
    "    if (data_dir / \"cache\").exists() == False:\n",
    "        (data_dir / \"cache\").mkdir()\n",
    "    df_prep.to_feather(data_dir / \"cache/speeches_prep.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep.to_csv(data_dir / \"cache/speeches_prep.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep[\"num_tokens\"] = df_prep[\"clean_text\"].apply(lambda x: len(tokenizer.encode(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_prep[\"num_tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_prep.copy().reset_index(drop=True).drop(columns=[\"init_clean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_parquet(data_dir / \"speechess.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studienarbeit-gw8hJpxJ-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ebb6e86b192b2c72706cccd5af746e68a11b43a742ad88cc72c60e2a13b42197"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
