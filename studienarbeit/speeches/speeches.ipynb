{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Politische Reden als Datenquelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "\n",
    "from studienarbeit.utils.cleaning import Cleaning\n",
    "from studienarbeit.utils.plots import Plots\n",
    "from studienarbeit.utils.sentiment import Sentiment\n",
    "from studienarbeit.utils.split_text import SplitText\n",
    "from studienarbeit.utils.load import EDataTypes\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from collections import Counter\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "sns.set(style=\"white\", palette=\"muted\", rc={\"figure.figsize\": (20, 8)})\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../../data/speeches\")\n",
    "data_type = EDataTypes.SPEECHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/party_colors.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "  party_palette = json.load(f)\n",
    "plots = Plots(data_type, data_dir, party_palette)\n",
    "sentiment = Sentiment()\n",
    "cleaning = Cleaning()\n",
    "split_text = SplitText()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "\n",
    "Im Folgenden wird der [Datensatz bestehend aus Bundestagsreden](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/FIKIBO), bereitgestellt von [Open Discourse](https://opendiscourse.de/) initial untersucht. Politische Reden, in diesem Fall aus dem deutschen Bundestag, sollen als ein Standbein als Trainingsdaten für das Klassifikationsproblem genutzt werden. Der Datensatz bietet den Vorteil, dass eine große Menge an gelabelten Texten zur Verfügung steht sowie alle möglichen Themenbereiche abdeckt, die im Laufe der Jahre im Bundestag debattiert wurden. Da die Reden deutlich länger sind als Tweets (siehe unten), muss eine Lösung gefunden werden, wie die Redetexte aufgeteilt werden können, um sie dem Modell als Input zur Verfügung zu stellen. Andererseits kann dies auche als Vorteil gesehen werden, da die Reden deutlich mehr Informationen enthalten als Tweets und somit dem Modell eine bessere Chance bieten, auch aufgrund inhaltlichen Zusammenhängen zu entscheiden."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `factions`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_factions = pd.read_feather(data_dir / \"src\" / \"factions.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_factions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die `factions`-Datei verknüpft die ID der Parteien mit deren Namen. Für die für uns relevanten Parteien sollten wir uns frühzeitig auf ein einheitliches Mapping zwischen Label und Partei einigen, um spätere Probleme zu vermeiden.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `politicians`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_politicians = pd.read_feather(data_dir / \"src\" / \"politicians.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_politicians"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die `politicians`-Datei verknüpft die ID der Politiker mit deren Namen inkl. weiteren Informationen. Da wir zunächst nur nach Parteien klassifizieren wollen, ist diese Datei für uns nicht relevant.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `electoral_terms`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_electoral_terms = pd.read_feather(data_dir / \"src\" / \"electoral_terms.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_electoral_terms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die `electoral_terms`-Datei verknüpft die ID der Wahlperioden mit derem Start- und Enddatum. Um in allen Datenquellen vergleichbare Themen, Sprache und Parteien zu haben, sollten alle Daten auf einen ähnlichen Zeitraum beschränkt werden. Da sich die uns zur Verfügung stehenden Tweet Daten auf die Bundestagswahl 2021 und die Wahlperiode 19 beziehen, sind vor allem Reden als der 19. Wahlperiode relevant.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `contributions`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contributions = pd.read_feather(data_dir / \"src\" / \"contributions_extended.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contributions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die `contributions`-Datei enthält Zwischenrufe oder sonstige Reaktionen im Plenum, die keine richtigen Reden sind. Da diese meist nur sehr kurz und nicht wirklich aussagekräftig sind, werden sie für uns nicht relevant sein."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `speeches`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches = pd.read_feather(data_dir / \"src\" / \"speeches.feather\", columns=[\"electoralTerm\", \"speechContent\", \"politicianId\", \"factionId\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie gerade angemerkt, sind für uns erstmal die Reden aus der 19. Wahlperiode relevant:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches = df_speeches[df_speeches[\"electoralTerm\"] == 19].reset_index(drop=True)\n",
    "df_speeches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus dieser Wahlperiode bleiben zunächst etwa 61.000 Reden übrig. Davon sind jedoch noch jene abzuziehen, die keiner Partei zugeordnet sind, weil beispielsweise das Präsidium des Bundestage gesprochen hat. Zudem wird mithilfe der `factionId` der Namen der Fraktion bestimmt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factions_of_interest = [0, 3, 4, 6, 13, 23]\n",
    "df_speeches = df_speeches[df_speeches[\"factionId\"].isin(factions_of_interest)]\n",
    "\n",
    "party_mapping = {\n",
    "    0: \"AfD\",\n",
    "    3: \"Grüne\",\n",
    "    4: \"Union\",\n",
    "    6: \"Linke\",\n",
    "    13: \"FDP\",\n",
    "    23: \"SPD\"\n",
    "}\n",
    "df_speeches[\"party\"] = df_speeches[\"factionId\"].map(party_mapping)\n",
    "df_speeches = df_speeches.drop(columns=[\"factionId\"])\n",
    "\n",
    "df_speeches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somit reduziert sich die Anzahl an verbleibender Reden auf knapp 29.000.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da der Wert von `electoralTerm` nun konstant ist, kann die Spalte gelöscht werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches = df_speeches.drop(columns=[\"electoralTerm\"])\n",
    "df_speeches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Anzahl an Reden pro Fraktion`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn man sich die Anzahl an Reden pro Fraktion anschaut, fällt auf, dass die Fraktionen der CDU/CSU und der SPD deutlich mehr Reden haben als die anderen Parteien, was auch zu erwarten ist. Im Zuge der Data Preparation muss hierzu sichergestellt werden, dass ein Ungleichgewicht vermieden wird.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches.groupby(\"party\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.party_count(df_speeches, title=\"Anzahl an Reden nach Partei\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Anzahl an Rednern pro Fraktion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.politician_count(df_speeches, title=\"Anzahl an Politikern nach Partei\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Häufige 3-grams`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for party in [\"AfD\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\", \"Union\"]:\n",
    "    df_current_party = df_speeches[df_speeches[\"party\"] == party]\n",
    "    ngram_counts = Counter(ngrams(\" \".join(df_current_party[\"speechContent\"].tolist()).split(), 3))\n",
    "    print(f\"{party}: \" + str(ngram_counts.most_common(5)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auffallend sind Formulierung zur Begrüßung zu Beginn der Rede, die häufig vorkommen. Diese können später entfernt werden."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Verteilung der Anzahl an...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_speeches[\"char_count\"] = df_speeches[\"speechContent\"].progress_apply(len).astype(\"int16\")\n",
    "df_speeches[\"word_count\"] = df_speeches[\"speechContent\"].progress_apply(lambda x : len(x.split())).astype(\"int16\")\n",
    "df_speeches[\"sentence_count\"] = df_speeches[\"speechContent\"].progress_apply(lambda x : len(sent_tokenize(x))).astype(\"int16\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Zeichen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.word_count(df_speeches, \"char_count\", \"Anzahl an Zeichen nach Partei\", 10000, \"Anzahl an Zeichen\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Wörtern`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.word_count(df_speeches, \"word_count\", \"Anzahl an Wörtern nach Partei\", 1300, \"Anzahl an Wörtern\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Sätzen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.word_count(df_speeches, \"sentence_count\", \"Anzahl an Sätzen nach Partei\", 100, \"Anzahl an Sätzen\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Sonderzeichen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce(lambda a, b: set((*a, *b)), df_speeches[\"speechContent\"].apply(np.array))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schaut man sich an, welche Zeichen in den Reden vorkommen, fällt auf, dass neben dem regulären Alphabet auch einige unerwünschte Sonderzeichen enthalten sind, die im Zuge der Data Preparation entfernt werden müssen.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = df_speeches.copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = df_prep[df_prep[\"politicianId\"] != -1]\n",
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = df_prep[df_prep[\"word_count\"] >= 200].reset_index(drop=True)\n",
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = df_prep.drop(columns=[\"char_count\", \"word_count\", \"sentence_count\"])\n",
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep.duplicated(subset=[\"speechContent\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = df_prep.drop_duplicates(subset=[\"speechContent\"]).reset_index(drop=True)\n",
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep.duplicated(subset=[\"speechContent\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = split_text.split_dataframe_texts(df_prep, \"speechContent\", 512)\n",
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_cleaning(text):\n",
    "    text = re.sub(\"[\\u2022\\u2023\\u25E6\\u2043\\u2219\\uf0b7\\u25fc]\\s\", \" \", text)\n",
    "    text = re.sub(\"({\\d*})\", \"\", text)\n",
    "    text = re.sub(\"\\(\\w*\\)\", \"\", text)\n",
    "    text = text.replace(\". –\", \". \")\n",
    "    \n",
    "    text = re.sub(\"\\n\", \" \", text)\n",
    "    text = re.sub(\"\\t\", \" \", text)\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep[\"clean_text\"] = df_prep[\"speechContent\"].progress_apply(lambda x: cleaning.clean_text(initial_cleaning(x), keep_punctuation=True, keep_upper=True)).astype(\"string[pyarrow]\")\n",
    "df_prep = df_prep.drop(columns=[\"speechContent\", \"politicianId\"])\n",
    "\n",
    "df_prep[\"tokenized_text\"] = df_prep[\"clean_text\"].progress_apply(lambda x: cleaning.filter_text(cleaning.lemma_text(x))).astype(\"string[pyarrow]\")\n",
    "\n",
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_prep.copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.groupby(\"party\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/party_encoding.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "  party_encoding = json.load(f)\n",
    "\n",
    "df_final[\"party\"] = df_final[\"party\"].map(party_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_parquet(data_dir / \"speeches.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studienarbeit-gw8hJpxJ-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ebb6e86b192b2c72706cccd5af746e68a11b43a742ad88cc72c60e2a13b42197"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
