{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets (Sältzer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from studienarbeit.utils import plots\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAST_MODE = False\n",
    "\n",
    "data_dir = Path(\"../../data/tweets\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "\n",
    "---\n",
    "\n",
    "Lorem\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\n",
    "    data_dir / \"tweets.parquet\",\n",
    "    columns=[\"screen_name\", \"created_at\", \"is_retweet\", \"text\", \"party\", \"birthyear\", \"gender\"],\n",
    "    use_nullable_dtypes=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(\n",
    "        lambda x: None if x == \"\" or x == \"NA\" or x == \"NA, NA\" or x == \"NA, NA, NA, NA, NA, NA, NA, NA\" else x\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above we can see that there are about 11k missing values in the `text` column. Regarding the `is_retweet` column, about 3k entries have missing values.\n",
    "\n",
    "Following we will delete the rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"text\", \"is_retweet\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following, we can check which columns represent categorical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_dict = {\n",
    "    \"screen_name\": \"category\",\n",
    "    \"created_at\": \"datetime64[ns]\",\n",
    "    \"is_retweet\": \"category\",\n",
    "    \"text\": \"string\",\n",
    "    \"party\": \"category\",\n",
    "    \"birthyear\": \"datetime64[ns]\",\n",
    "    \"gender\": \"category\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(convert_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=True, memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\", datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.plot_party_count(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandarallel import pandarallel\n",
    "from studienarbeit.utils.cleaning import CleanText\n",
    "from textblob_de.sentiments import PatternAnalyzer\n",
    "\n",
    "pandarallel.initialize(progress_bar=True, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = CleanText()\n",
    "sentiment = PatternAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_pipeline(df: pd.DataFrame):\n",
    "    # Remove tweets from parties that are not in the Bundestag\n",
    "    df = df[df[\"party\"] != \"Parteilos\"]\n",
    "\n",
    "    # Group CDU and CSU as Union\n",
    "    df[\"party\"] = df[\"party\"].replace(\"CSU\", \"UNION\")\n",
    "    df[\"party\"] = df[\"party\"].replace(\"CDU\", \"UNION\")\n",
    "    df[\"party\"] = df[\"party\"].cat.remove_unused_categories()\n",
    "\n",
    "    # Fix labels for retweets\n",
    "    df[\"is_retweet\"] = df[\"is_retweet\"].replace(\"FALSE\", False)\n",
    "    df[\"is_retweet\"] = df[\"is_retweet\"].replace(\"TRUE\", True)\n",
    "    df[\"is_retweet\"] = df[\"is_retweet\"].astype(\"bool\")\n",
    "\n",
    "    # Apply cleaning pipeline\n",
    "    df[\"clean_text\"] = df[\"text\"].parallel_apply(lambda x: clean.clean_text(x)).astype(\"string\")\n",
    "    df[\"tokenized_text\"] = (\n",
    "        df[\"clean_text\"].parallel_apply(lambda x: clean.remove_stopwords(clean.stemm_text(x))).astype(\"string\")\n",
    "    )\n",
    "\n",
    "    # Count the number of words in the tweet\n",
    "    df[\"word_count\"] = df[\"clean_text\"].parallel_apply(lambda x: len(x.split())).astype(\"int16\")\n",
    "\n",
    "    # Calculate the sentiment of the tweets\n",
    "    # df[\"sentiment\"] = df[\"clean_text\"].parallel_apply(lambda x: sentiment.analyze(x).polarity).astype(\"float32\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either load the cached data or process the raw tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FAST_MODE and (data_dir / \"cache/tweets_prep.parquet\").exists():\n",
    "    df_prep = pd.read_parquet(data_dir / \"cache/tweets_prep.parquet\")\n",
    "else:\n",
    "    df_prep = prep_pipeline(df.copy())  # .sample(10000, random_state=42, ignore_index=True)\n",
    "\n",
    "    if (data_dir / \"cache\").exists() == False:\n",
    "        (data_dir / \"cache\").mkdir()\n",
    "    df_prep.to_parquet(data_dir / \"cache/tweets_prep.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (data_dir / \"cache\").exists() == False:\n",
    "    (data_dir / \"cache\").mkdir()\n",
    "df_prep.to_parquet(data_dir / \"cache/tweets_prep_w_sent.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = pd.read_parquet(data_dir / \"cache/tweets_prep_wo_sent.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = pd.read_parquet(data_dir / \"cache/tweets_prep_w_sent.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from spacy_sentiws import spaCySentiWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_nlp_ger = spacy.load(\"de_core_news_md\", exclude=[\"tagger\", \"parser\", \"senter\", \"ner\"]) \n",
    "spacy_nlp_ger.add_pipe(\"sentiws\", config={'sentiws_path': '../../data/sentiws/'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep[\"sentiment\"] = df_prep[\"clean_text\"].parallel_apply(lambda x: np.mean([token._.sentiws if token._.sentiws != None for token in spacy_nlp_ger(x)])).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep.describe(include=\"all\", datetime_is_numeric=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of tweets with less than 5 words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Found {len(df_prep.loc[df_prep['word_count'] < 5])} tweets with less than 5 words...\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of tweets labeled as retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The dataset contains {len(df_prep.loc[df_prep['is_retweet'] == True])} retweets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering_pipeline(df):\n",
    "  df = df[df[\"word_count\"] >= 5]\n",
    "  df = df[df[\"is_retweet\"] == False]\n",
    "  \n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = filtering_pipeline(df_prep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_map = {\n",
    "    \"AfD\": 0,\n",
    "    \"FDP\": 1,\n",
    "    \"DIE GRÜNEN\": 2,\n",
    "    \"DIE LINKE\": 3,\n",
    "    \"SPD\": 4,\n",
    "    \"UNION\": 5,\n",
    "}\n",
    "\n",
    "df_prep[\"party\"] = df_prep[\"party\"].map(party_map).astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_map = {\n",
    "    \"male\": 0,\n",
    "    \"female\": 1,\n",
    "}\n",
    "\n",
    "df_prep[\"gender\"] = df_prep[\"gender\"].map(gender_map).astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep.info(verbose=True, memory_usage=\"deep\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.plot_party_count(df_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.plot_sentiment(df_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.plot_word_count(df_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.plot_gender(df_prep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep.describe(include=\"all\", datetime_is_numeric=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling = df_prep[[\"clean_text\", \"tokenized_text\", \"party\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling.to_parquet(data_dir / \"cache/tweets_modeling.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "7abe641ef5c60e7b2b79f06dad82c6b1ae6b3c4f8500bc012ee8285dc22561c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
