{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets (Sältzer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from studienarbeit.utils.plots import Plots\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAST_MODE = True\n",
    "\n",
    "data_dir = Path(\"../../data/tweets\")\n",
    "plot = Plots()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "\n",
    "---\n",
    "\n",
    "Lorem\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\n",
    "    data_dir / \"tweets.parquet\",\n",
    "    columns=[\"screen_name\", \"created_at\", \"is_retweet\", \"text\", \"party\", \"birthyear\", \"gender\"],\n",
    "    use_nullable_dtypes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(\n",
    "        lambda x: None if x == \"\" or x == \"NA\" or x == \"NA, NA\" or x == \"NA, NA, NA, NA, NA, NA, NA, NA\" else x\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above we can see that there are about 11k missing values in the `text` column. Regarding the `is_retweet` column, about 3k entries have missing values.\n",
    "\n",
    "Following we will delete the rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"text\", \"is_retweet\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following, we can check which columns represent categorical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean duplicated rows (some tweets seem to be scraped twice at different days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=[\"screen_name\", \"is_retweet\", \"text\", \"party\", \"birthyear\", \"gender\"], keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"party\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_dict = {\n",
    "    \"screen_name\": \"category\",\n",
    "    \"created_at\": \"datetime64[ns]\",\n",
    "    \"is_retweet\": \"category\",\n",
    "    \"text\": \"string[pyarrow]\",\n",
    "    \"party\": \"category\",\n",
    "    \"birthyear\": \"datetime64[ns]\",\n",
    "    \"gender\": \"category\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(convert_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=True, memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\", datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from pandarallel import pandarallel\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from nltk import ngrams\n",
    "from studienarbeit.utils.cleaning import Cleaning\n",
    "from studienarbeit.utils.sentiment import Sentiment\n",
    "\n",
    "tqdm.pandas()\n",
    "pandarallel.initialize(progress_bar=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = Cleaning()\n",
    "sentiment = Sentiment()\n",
    "\n",
    "cache_file = data_dir / \"cache/tweets_prep.parquet\"\n",
    "\n",
    "party_encoding = {\n",
    "    \"AfD\": 0,\n",
    "    \"FDP\": 1,\n",
    "    \"DIE GRÜNEN\": 2,\n",
    "    \"DIE LINKE\": 3,\n",
    "    \"SPD\": 4,\n",
    "    \"UNION\": 5,\n",
    "}\n",
    "gender_encoding = {\n",
    "    \"male\": 0,\n",
    "    \"female\": 1,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_pipeline(df: pd.DataFrame, min_word_count: int = 5):\n",
    "    # Group CDU and CSU as Union\n",
    "    df[\"party\"] = df[\"party\"].replace(\"CSU\", \"UNION\")\n",
    "    df[\"party\"] = df[\"party\"].replace(\"CDU\", \"UNION\")\n",
    "    df[\"party\"] = df[\"party\"].cat.remove_unused_categories()\n",
    "\n",
    "    # Fix labels for retweets\n",
    "    df[\"is_retweet\"] = df[\"is_retweet\"].replace(\"FALSE\", False)\n",
    "    df[\"is_retweet\"] = df[\"is_retweet\"].replace(\"TRUE\", True)\n",
    "    df[\"is_retweet\"] = df[\"is_retweet\"].astype(\"bool\")\n",
    "\n",
    "    # Remove tweets from parties that are not in the Bundestag and/or retweets\n",
    "    print(f\"The dataset contains {len(df.loc[df['is_retweet'] == True])} retweets.\")\n",
    "    df = df.loc[(df[\"party\"] != \"Parteilos\") & (df[\"is_retweet\"] == False)]\n",
    "\n",
    "    # Encode party and gender\n",
    "    df[\"party\"] = df[\"party\"].map(party_encoding).astype(\"int8\")\n",
    "    df[\"gender\"] = df[\"gender\"].map(gender_encoding).astype(\"int8\")\n",
    "\n",
    "    # Apply cleaning pipeline\n",
    "    df[\"clean_text\"] = df[\"text\"].parallel_apply(lambda x: clean.clean_text(x)).astype(\"string[pyarrow]\")\n",
    "    df[\"tokenized_text\"] = (\n",
    "        df[\"clean_text\"].parallel_apply(lambda x: clean.remove_stopwords(clean.stemm_text(x))).astype(\"string[pyarrow]\")\n",
    "    )\n",
    "\n",
    "    # Count the number of words and tokens in the tweet\n",
    "    df[\"word_count\"] = df[\"clean_text\"].parallel_apply(lambda x: len(x.split())).astype(\"int16\")\n",
    "    df[\"token_count\"] = df[\"tokenized_text\"].parallel_apply(lambda x: len(x)).astype(\"int16\")\n",
    "\n",
    "    # Filter out tweets that are too short\n",
    "    print(\n",
    "        f\"Found {len(df.loc[df['word_count'] < min_word_count])} tweets with less than {min_word_count} words...\"\n",
    "    )  # df['token_count'] < 5\n",
    "    df = df.loc[df[\"word_count\"] >= min_word_count]  # df['token_count'] >= 5\n",
    "\n",
    "    # Calculate the sentiment of the tweets\n",
    "    df[\"sentiment\"] = df[\"clean_text\"].progress_apply(sentiment.predict_sentiment).astype(\"category\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either load the cached data or process the raw tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FAST_MODE and cache_file.exists():\n",
    "    df_prep = pd.read_parquet(cache_file)\n",
    "else:\n",
    "    df_prep = prep_pipeline(df.sample(10000, random_state=42).copy()).reset_index(drop=True)\n",
    "\n",
    "    if (data_dir / \"cache\").exists() == False:\n",
    "        (data_dir / \"cache\").mkdir()\n",
    "    df_prep.to_parquet(cache_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for n-grams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(\n",
    "    list(itertools.chain.from_iterable(df_prep[\"text\"].str.split().progress_apply(lambda x: ngrams(x, 3))))\n",
    ").most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep.info(verbose=True, memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep.describe(include=\"all\", datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.party_count(df_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.sentiment(df_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.word_count(df_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.gender(df_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.user_count(df_prep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling = df_prep[[\"clean_text\", \"tokenized_text\", \"party\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modeling.to_parquet(data_dir / \"cache/tweets_modeling.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "7abe641ef5c60e7b2b79f06dad82c6b1ae6b3c4f8500bc012ee8285dc22561c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
