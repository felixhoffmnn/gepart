{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parteiprogramme als Datenquelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import seaborn as sns\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from pdfminer.high_level import extract_text\n",
    "from studienarbeit.utils.cleaning import Cleaning\n",
    "from studienarbeit.utils.plots import Plots\n",
    "from studienarbeit.utils.sentiment import Sentiment\n",
    "from studienarbeit.utils.load import EDataTypes\n",
    "from collections import Counter\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "sns.set(style=\"white\", palette=\"muted\", rc={\"figure.figsize\": (20, 8)})\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../../data/party_programs\")\n",
    "data_type = EDataTypes.PARTY_PROGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/party_colors.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "  party_palette = json.load(f)\n",
    "plots = Plots(data_type, data_dir, party_palette)\n",
    "sentiment = Sentiment()\n",
    "cleaning = Cleaning()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business Understanding\n",
    "\n",
    "In unseren Untersuchungszeitraum von 2017 bis 2021, die 19. Wahlperiode des Deutschen Bundestages, fallen neben den Bundestagswahlen 2017 und 2021 die Europawahl 2019 sowie zahlreiche Landtagswahlen, zu denen die antretenden Parteien jeweils ein Wahlprogramm veröffentlichen. Diese Wahlprogramme sind für uns von Interesse, da sie umfangreiche Texte mit der jeweiligen politischen Prägung zu einer großen Bandbreite an Themen bereitstellen und damit viele Informationen dazu bieten, welche Themen von einer Partei immer wieder mit Priorität behandelt werden und welche Sprache dabei verwendet wird. Die Wahlprogramme können üblicherweise als PDF-Datei von der Webseite der jeweiligen Partei bezogen werden."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Beschaffung der Daten"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Summe stehen 82 Wahlprogramme von AfD, FDP, Grünen, Linken, SPD und CDU/CSU zur Verfügung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_party_programs_overview = pd.read_csv(data_dir / \"overview.csv\", delimiter=\";\")\n",
    "df_party_programs_overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hinweis: Nicht parsbare Wahlprogramme\n",
    "\n",
    "Der entwickelte Algorithmus zum Auslesen des Texten und parsen der einzelnen Paragraphen eines Wahlprogramms funktioniert für die meisten gegebenen Wahlprogramme im PDF-Format. Es gibt jedoch einige Ausnahmen, bei denen entweder der Text nicht erkannt werden kann oder die Formatierung so ist, dass der Algorithmus ohne erhebliche Anpassungen nicht funktioniert. Dies betrifft die folgenden Wahlprogramme:\n",
    "- AfD + FDP LTW MV 21\n",
    "- FDP + CDU LTW 21 Berlin\n",
    "- AfD LTW 21 Sachsen-Anhalt\n",
    "- Grüne LTW 21 Bade-Württemberg\n",
    "- SPD LTW 21 Rheinland-Pfalz\n",
    "- SPD + CDU LTW 20 Hamburg\n",
    "- AfD LTW 19 Thüringen\n",
    "- FDP LTW 19 Brandenburg\n",
    "- AfD Europawahl 2019\n",
    "- AfD + SPD LTW 18 Hessen\n",
    "- AfD + Linke LTW 18 Bayern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_phrases_from_file(text, party):\n",
    "    df_phrases = pd.read_csv(data_dir / \"src\" / party / \"phrases.csv\", delimiter=\";\", keep_default_na=False)\n",
    "    for _, row in df_phrases.iterrows():\n",
    "        text = re.sub(row[\"phrase\"], row[\"new\"], text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "def initial_cleaning(text, lower=False, gender_symbols=[\"*\", \":\"]):\n",
    "    if lower:\n",
    "        text = text.lower()\n",
    "    \n",
    "    text = text.replace(\"-\\n\", \"- \")\n",
    "    text = re.sub(\"-\\s+\", \"-\", text)\n",
    "    text = text.replace(\"-oder\", \"- oder\")\n",
    "    text = text.replace(\"-und\", \"- und\")\n",
    "    text = re.sub(\"([a-zßäöü])-([a-zßäöü])\", r\"\\1\\2\", text)\n",
    "    text = re.sub(\"[\\u2022\\u2023\\u25E6\\u2043\\u2219\\uf0b7\\u25fc]\\s\", \"\", text)\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    text = cleaning.clean_gender(text, gender_symbols)\n",
    "        \n",
    "    # Party specific cleaning\n",
    "    for party in [\"AfD\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\", \"Union\"]:\n",
    "        text = remove_phrases_from_file(text, party)\n",
    "    \n",
    "    # Remove possible newly occured double spaces\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_paragraphs(all_paragraphs):\n",
    "    tmp = []\n",
    "    for p in all_paragraphs:        \n",
    "        if (p[-1] in [\".\", \"!\", \"?\"]):\n",
    "            if ((len(tmp) == 0) and (p[0].islower())):\n",
    "                continue\n",
    "            tmp.append(p)\n",
    "            yield \" \".join(tmp)\n",
    "            tmp = []\n",
    "        elif (p[-1] == \":\"): \n",
    "            continue\n",
    "        elif ((p[0].isupper()) and (tmp == [])):\n",
    "            tmp.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_paragraphs = pd.DataFrame(columns=[\"text_orig\", \"party\"])\n",
    "\n",
    "for _, program in df_party_programs_overview.iterrows():\n",
    "    all_text = extract_text(data_dir / \"src\" / program[\"party\"] / f\"{program['election']}.pdf\", page_numbers=range(program[\"first_page\"] - 1, program[\"last_page\"]))\n",
    "\n",
    "    all_paragraphs = list(filter(lambda x : 150 <= len(x), all_text.split(\"\\n\\n\")))\n",
    "        \n",
    "    all_paragraphs = [initial_cleaning(x) for x in all_paragraphs]\n",
    "    all_paragraphs = list(filter(lambda x : 150 <= len(x), all_paragraphs))\n",
    "    all_paragraphs = merge_paragraphs(all_paragraphs)\n",
    "\n",
    "    df_current_party = pd.DataFrame(all_paragraphs, columns=[\"text_orig\"])\n",
    "    df_current_party[\"party\"] = program[\"party\"]\n",
    "    df_current_party[\"election_type\"] = program[\"election\"][:3]\n",
    "    df_current_party[\"election\"] = program[\"election\"]\n",
    "\n",
    "    df_all_paragraphs = pd.concat([df_all_paragraphs, df_current_party])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_paragraphs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_understanding = df_all_paragraphs.copy().reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Anzahl an Paragraphen pro Partei`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.party_count(df_understanding, title=\"Anzahl an Paragraphen nach Partei\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Anzahl an Paragraphen nach Art der Wahl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.grouped_party_count(df_understanding, \"election_type\", \"Anzahl an Paragraphen nach Art der Wahl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_understanding.groupby(\"party\").count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Häufigste 3-grams`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for party in [\"AfD\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\", \"Union\"]:\n",
    "    df_current_party = df_understanding[df_understanding[\"party\"] == party]\n",
    "    ngram_counts = Counter(ngrams(\" \".join(df_current_party[\"text_orig\"].tolist()).split(), 3))\n",
    "    print(f\"{party}: \" + str(ngram_counts.most_common(5)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Verteilung der Anzahl an...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_understanding[\"char_count\"] = df_understanding[\"text_orig\"].progress_apply(len).astype(\"int16\")\n",
    "df_understanding[\"word_count\"] = df_understanding[\"text_orig\"].progress_apply(lambda x : len(x.split())).astype(\"int16\")\n",
    "df_understanding[\"sentence_count\"] = df_understanding[\"text_orig\"].progress_apply(lambda x : len(sent_tokenize(x))).astype(\"int16\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Zeichen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.word_count(df_understanding, \"char_count\", \"Anzahl an Zeichen nach Partei\", 2500, \"Anzahl an Zeichen\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Wörtern`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.word_count(df_understanding, \"word_count\", \"Anzahl an Wörtern nach Partei\", 300, \"Anzahl an Wörtern\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Sätzen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.word_count(df_understanding, \"sentence_count\", \"Anzahl an Sätzen nach Partei\", 15, \"Anzahl an Sätzen\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = df_all_paragraphs.copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep[\"clean_text\"] = df_prep[\"text_orig\"].progress_apply(lambda x: cleaning.clean_text(x, keep_punctuation=True, keep_upper=True)).astype(\"string[pyarrow]\")\n",
    "df_prep[\"tokenized_text\"] = df_prep[\"clean_text\"].progress_apply(lambda x: cleaning.filter_text(cleaning.lemma_text(x))).astype(\"string[pyarrow]\")\n",
    "\n",
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep.groupby(\"party\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep.duplicated(subset=[\"clean_text\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = df_prep.drop_duplicates(subset=[\"clean_text\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep.duplicated(subset=[\"clean_text\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_prep.copy().reset_index(drop=True).drop(columns=[\"text_orig\", \"election_type\", \"election\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/party_encoding.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "  party_encoding = json.load(f)\n",
    "  df_final[\"party\"] = df_final[\"party\"].map(party_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_parquet(data_dir / \"party_programs.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studienarbeit-gw8hJpxJ-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ebb6e86b192b2c72706cccd5af746e68a11b43a742ad88cc72c60e2a13b42197"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
