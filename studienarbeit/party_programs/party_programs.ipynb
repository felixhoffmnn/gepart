{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parteiprogramme als Datenquelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import seaborn as sns\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from pandarallel import pandarallel\n",
    "from pdfminer.high_level import extract_text\n",
    "from studienarbeit.utils.cleaning import CleanText\n",
    "from matplotlib import pyplot as plt\n",
    "from textblob_de.sentiments import PatternAnalyzer\n",
    "from collections import Counter\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "sns.set(style=\"white\", palette=\"muted\", rc={\"figure.figsize\": (20, 8)})\n",
    "pandarallel.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAST_MODE = True\n",
    "data_dir = Path(\"../../data/party_programs\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business Understanding\n",
    "\n",
    "In unseren Untersuchungszeitraum von 2017 bis 2021, die 19. Wahlperiode des Deutschen Bundestages, fallen neben den Bundestagswahlen 2017 und 2021 die Europawahl 2019 sowie zahlreiche Landtagswahlen, zu denen die antretenden Parteien jeweils ein Wahlprogramm veröffentlichen. Diese Wahlprogramme sind für uns von Interesse, da sie umfangreiche Texte mit der jeweiligen politischen Prägung zu einer großen Bandbreite an Themen bereitstellen und damit viele Informationen dazu bieten, welche Themen von einer Partei immer wieder mit Priorität behandelt werden und welche Sprache dabei verwendet wird. Die Wahlprogramme können üblicherweise als PDF-Datei von der Webseite der jeweiligen Partei bezogen werden."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Beschaffung der Daten"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Summe stehen 82 Wahlprogramme von AfD, FDP, Grünen, Linken, SPD und CDU/CSU zur Verfügung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_party_programs_overview = pd.read_csv(data_dir / \"overview.csv\", delimiter=\";\")\n",
    "df_party_programs_overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hinweis: Nicht parsbare Wahlprogramme\n",
    "\n",
    "Der entwickelte Algorithmus zum Auslesen des Texten und parsen der einzelnen Paragraphen eines Wahlprogramms funktioniert für die meisten gegebenen Wahlprogramme im PDF-Format. Es gibt jedoch einige Ausnahmen, bei denen entweder der Text nicht erkannt werden kann oder die Formatierung so ist, dass der Algorithmus ohne erhebliche Anpassungen nicht funktioniert. Dies betrifft die folgenden Wahlprogramme:\n",
    "- AfD + FDP LTW MV 21\n",
    "- FDP + CDU LTW 21 Berlin\n",
    "- AfD LTW 21 Sachsen-Anhalt\n",
    "- Grüne LTW 21 Bade-Württemberg\n",
    "- SPD LTW 21 Rheinland-Pfalz\n",
    "- SPD + CDU LTW 20 Hamburg\n",
    "- AfD LTW 19 Thüringen\n",
    "- FDP LTW 19 Brandenburg\n",
    "- AfD Europawahl 2019\n",
    "- AfD + SPD LTW 18 Hessen\n",
    "- AfD + Linke LTW 18 Bayern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_cleaning(text, lower=False, gender_symbols=[\"*\", \":\"]):\n",
    "    if lower:\n",
    "        text = text.lower()\n",
    "    \n",
    "    text = text.replace(\"-\\n\", \"- \")\n",
    "    text = re.sub(\"-\\s+\", \"-\", text)\n",
    "    text = text.replace(\"-oder\", \"- oder\")\n",
    "    text = text.replace(\"-und\", \"- und\")\n",
    "    text = re.sub(\"([a-zßäöü])-([a-zßäöü])\", r\"\\1\\2\", text)\n",
    "    text = re.sub(\"[\\u2022\\u2023\\u25E6\\u2043\\u2219\\uf0b7\\u25fc]\\s\", \"\", text)\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Clean words with 'Genderstern'\n",
    "    for symbol in gender_symbols:\n",
    "        text = re.sub(f\"([a-zßäöü])\\{symbol}innen([a-zßäöü]?)\", r\"\\1\\2\", text)\n",
    "        text = re.sub(f\"([a-zßäöü])\\{symbol}in([a-zßäöü]?)\", r\"\\1\\2\", text)\n",
    "        text = text.replace(f\"Sinti{symbol}zze und Rom{symbol}nja\", \"Sinti und Roma\")\n",
    "        text = text.replace(f\"der{symbol}die\", \"der\")\n",
    "        text = text.replace(f\"die{symbol}der\", \"der\")\n",
    "        text = text.replace(f\"den{symbol}die\", \"den\")\n",
    "        text = text.replace(f\"dem{symbol}der\", \"dem\")\n",
    "        text = text.replace(f\"der{symbol}s\", \"des\")\n",
    "        text = text.replace(f\"eines{symbol}einer\", \"eines\")\n",
    "        text = text.replace(f\"einer{symbol}s\", \"eines\")\n",
    "        text = text.replace(f\"ihre{symbol}seine\", \"seine\")\n",
    "        text = text.replace(f\"seiner{symbol}ihrer\", \"seiner\")\n",
    "        text = text.replace(f\"jeder{symbol}m\", \"jedem\")\n",
    "        text = text.replace(f\"Sie{symbol}Er\", \"Er\")\n",
    "        text = text.replace(f\"des{symbol}der\", \"des\")\n",
    "        text = text.replace(f\"welchem{symbol}welcher\", \"welchem\")\n",
    "        text = text.replace(f\"{symbol}r\", \"r\")\n",
    "        text = text.replace(f\"{symbol}n\", \"n\")\n",
    "        text = text.replace(f\"{symbol}e\", \"n\")\n",
    "        \n",
    "    # Party specific cleaning\n",
    "    # AfD\n",
    "    text = text.replace(\"die AfD\", \"wir\")\n",
    "    text = text.replace(\"Die AfD\", \"Wir\")\n",
    "    \n",
    "    # FDP\n",
    "    text = text.replace(\"wir freien demokraten\", \"wir\")\n",
    "    text = text.replace(\"Freie Demokraten\", \"\")\n",
    "    \n",
    "    # Greens\n",
    "    text = re.sub(\"Bundestagswahlprogramm 2021(.*)Bundestagswahlprogramm 2021\", \"\", text)\n",
    "    text = re.sub(\"Bundestagswahlprogramm 2021BÜNDNIS 90 / DIE GRÜNENKapitel\\s\\d+\", \"\", text)\n",
    "    text = text.replace(\"Bundestagswahlprogramm 2021BÜNDNIS 90 / DIE GRÜNENEpilog\", \"\")\n",
    "    text = text.replace(\"Bundestagswahlprogramm 2021BÜNDNIS 90 / DIE GRÜNENEinleitung\", \"\")\n",
    "    text = text.replace(\"Bereit, weil Ihr es seid.\", \"\")\n",
    "    text = text.replace(\"bündnis 90/die grünen in sachsenlandtagswahlprogramm 2019\", \"\")\n",
    "    text = text.replace(\"wir grüne\", \"wir\")\n",
    "    text = re.sub(\"bürgerschaftswahlprogramm 2019(.*)bürgerschaftswahlprogramm 2019bündnis 90/die grünen landesverband bremen\", \"\", text)\n",
    "    text = text.replace(\"präambelbürgerschaftswahlprogramm 2019bündnis 90/die grünen landesverband bremen\", \"\")\n",
    "    text = text.replace(\"ökologischbürgerschaftswahlprogramm 2019bündnis 90/die grünen landesverband bremenmehrnützt allen \", \"\")\n",
    "    text = text.replace(\"gerechtbürgerschaftswahlprogramm 2019bündnis 90/die grünen landesverband bremenmehrnützt allen \", \"\")\n",
    "    text = text.replace(\"weltoffenbürgerschaftswahlprogramm 2019bündnis 90/die grünen landesverband bremenmehrnützt allen \", \"\")\n",
    "    text = text.replace(\"bündnis 90/die grünen\", \"wir\")\n",
    "    text = text.replace(\"europas versprechen erneuern.europawahlprogramm 2019wirpräambel\", \"\")\n",
    "    text = text.replace(\"europawahlprogramm 2019europawahlprogramm 2019wirpräambel\", \"\")\n",
    "    text = text.replace(\"europas versprechen erneuern.europawahlprogramm 2019wirerhalten, was uns erhält\", \"\")\n",
    "    text = text.replace(\"europawahlprogramm 2019europawahlprogramm 2019wirerhalten, was uns erhält\", \"\")\n",
    "    text = text.replace(\"europawahlprogramm 2019wirstärken, was uns zusammenhält\", \"\")\n",
    "    text = text.replace(\"europawahlprogramm 2019\", \"\")\n",
    "    text = text.replace(\"bayerns lebensgrundlagen erhaltenprogramm für die bayerische landtagswahl am 14. oktober 2018\", \"\")\n",
    "    text = text.replace(\"bayern – land der chancen für alleprogramm für die bayerische landtagswahl am 14. oktober 2018\", \"\")\n",
    "    text = text.replace(\"bayern – bunt, frei, sicherprogramm für die bayerische landtagswahl am 14. oktober 2018\", \"\")\n",
    "    text = text.replace(\"bayern und die welt – zusammenhalt macht stark programm für die bayerische landtagswahl am 14. oktober 2018\", \"\")\n",
    "    text = text.replace(\"programm für die bayerische landtagswahl am 14. oktober 2018bayerns lebensgrundlagen erhalten\", \"\")\n",
    "    text = text.replace(\"programm für die bayerische landtagswahl am 14. oktober 2018bayern – land der chancen für alle\", \"\")\n",
    "    text = text.replace(\"programm für die bayerische landtagswahl am 14. oktober 2018bayern – bunt, frei, sicher\", \"\")\n",
    "    text = text.replace(\"programm für die bayerische landtagswahl am 14. oktober 2018bayern und die welt – zusammenhalt macht stark\", \"\")\n",
    "    \n",
    "    # Linke\n",
    "    text = text.replace(\"DIE LINKE\", \"Wir\")\n",
    "    \n",
    "    # SPD\n",
    "    text = re.sub(\"Das Zukunftsprogramm der SPDKapitel\\s\\dSPD-Parteivorstand 2021\", \"\", text)\n",
    "    text = text.replace(\"die spd\", \"wir\")\n",
    "    \n",
    "    # Union\n",
    "    text = text.replace(\"CDU und CSU\", \"wir\")\n",
    "    text = re.sub(\"\\d+\\.\\d+\", \"\", text)\n",
    "    \n",
    "    # Remove possible newly occured double spaces\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_paragraphs(all_paragraphs):\n",
    "    tmp = []\n",
    "    for p in all_paragraphs:        \n",
    "        if (p[-1] in [\".\", \"!\", \"?\"]):\n",
    "            if ((len(tmp) == 0) and (p[0].islower())):\n",
    "                continue\n",
    "            tmp.append(p)\n",
    "            yield \" \".join(tmp)\n",
    "            tmp = []\n",
    "        elif (p[-1] == \":\"): \n",
    "            continue\n",
    "        elif ((p[0].isupper()) and (tmp == [])):\n",
    "            tmp.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_paragraphs = pd.DataFrame(columns=[\"text_orig\", \"party\"])\n",
    "\n",
    "for _, program in df_party_programs_overview.iterrows():\n",
    "    all_text = extract_text(data_dir / \"src\" / program[\"party\"] / f\"{program['election']}.pdf\", page_numbers=range(program[\"first_page\"] - 1, program[\"last_page\"]))\n",
    "\n",
    "    all_paragraphs = list(filter(lambda x : 150 <= len(x), all_text.split(\"\\n\\n\")))\n",
    "        \n",
    "    all_paragraphs = [initial_cleaning(x) for x in all_paragraphs]\n",
    "    all_paragraphs = list(filter(lambda x : 150 <= len(x), all_paragraphs))\n",
    "    all_paragraphs = merge_paragraphs(all_paragraphs)\n",
    "    all_paragraphs = [initial_cleaning(x, lower=True) for x in all_paragraphs]\n",
    "\n",
    "    df_current_party = pd.DataFrame(all_paragraphs, columns=[\"text_orig\"])\n",
    "    df_current_party[\"party\"] = program[\"party\"]\n",
    "    df_current_party[\"election_type\"] = program[\"election\"][:3]\n",
    "    df_current_party[\"election\"] = program[\"election\"]\n",
    "\n",
    "    df_all_paragraphs = pd.concat([df_all_paragraphs, df_current_party])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_paragraphs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_understanding = df_all_paragraphs.copy().reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Anzahl an Paragraphen pro Partei`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"party\", data=df_understanding)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Anzahl der Paragraphen pro Art der Wahl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"party\", hue=\"election_type\", data=df_understanding)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Häufigste 3-grams`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for party in [\"AfD\", \"FDP\", \"Grüne\", \"Linke\", \"SPD\", \"Union\"]:\n",
    "    df_current_party = df_understanding[df_understanding[\"party\"] == party]\n",
    "    party_text = \" \".join(df_current_party[\"text_orig\"].tolist())\n",
    "    ngram_counts = Counter(ngrams(party_text.split(), 3))\n",
    "    print(f\"{party}: \" + str(ngram_counts.most_common(5)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Verteilung der Anzahl an...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_understanding[\"char_count\"] = df_understanding[\"text_orig\"].parallel_apply(lambda x : len(x))\n",
    "df_understanding[\"word_count\"] = df_understanding[\"text_orig\"].parallel_apply(lambda x : len(x.split()))\n",
    "df_understanding[\"sentence_count\"] = df_understanding[\"text_orig\"].parallel_apply(lambda x : len(sent_tokenize(x)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Zeichen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_understanding[\"char_count\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Wörtern`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_understanding[\"word_count\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Sätzen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_understanding[\"sentence_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"oliverguhr/german-sentiment-bert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_understanding[\"num_tokens\"] = df_understanding[\"text_orig\"].apply(lambda x: len(tokenizer.encode(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_understanding[\"num_tokens\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = df_all_paragraphs.copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FAST_MODE and (data_dir / \"cache/party_programs_prep.feather\").exists():\n",
    "    df_prep = pd.read_feather(data_dir / \"cache/party_programs_prep.feather\")\n",
    "else:\n",
    "    clean = CleanText()\n",
    "\n",
    "    df_prep[\"clean_text\"] = df_prep[\"text_orig\"].parallel_apply(lambda x: clean.clean_text(x, True))\n",
    "    df_prep[\"tokenized_text\"] = df_prep[\"clean_text\"].parallel_apply(lambda x: clean.remove_stopwords(clean.stemm_text(x)))\n",
    "\n",
    "    if (data_dir / \"cache\").exists() == False:\n",
    "        (data_dir / \"cache\").mkdir()\n",
    "    df_prep.to_feather(data_dir / \"cache/party_programs_prep.feather\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_prep.copy().reset_index(drop=True).drop(columns=[\"text_orig\", \"election_type\", \"election\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/parties.json\", \"r\") as f:\n",
    "  party_encoding = json.load(f)\n",
    "  df_final[\"party\"] = df_final[\"party\"].map(party_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_parquet(data_dir / \"party_programs.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studienarbeit-gw8hJpxJ-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ebb6e86b192b2c72706cccd5af746e68a11b43a742ad88cc72c60e2a13b42197"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
